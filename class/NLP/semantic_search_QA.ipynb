{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b4f22b",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/NLP/semantic_search_QA.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/NLP/semantic_search_QA.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9871bad",
   "metadata": {},
   "source": [
    "# Semantic search & QA\n",
    "\n",
    "In this notebook, we'll introduce semantic search and question-answering using [`sentence-transformers`](https://www.sbert.net/), a Python library for state-of-the-art sentence, text and image embeddings. These embeddings are useful for semantic similarity tasks, such as information retrieval and question-answering systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the sentence-transformers library\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbabcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import time\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d00ed1",
   "metadata": {},
   "source": [
    "We'll use a pre-trained Sentence Transformer model to generate sentence embeddings. Many pre-trained models are available [here](https://www.sbert.net/docs/pretrained_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1aab1",
   "metadata": {},
   "source": [
    "For our semantic search and question-answering task, we need a list of documents or paragraphs to search through for relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample paragraphs\n",
    "paragraphs = [\n",
    "    \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\",\n",
    "    \"The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor within New York City, in the United States.\",\n",
    "    \"The Great Wall of China is a series of fortifications made of stone, brick, tamped earth, wood, and other materials, generally built along an east-to-west line across the historical northern borders of China.\",\n",
    "    \"The Colosseum, also known as the Flavian Amphitheatre, is an oval amphitheatre in the centre of the city of Rome, Italy.\",\n",
    "    \"The Taj Mahal is an ivory-white marble mausoleum on the southern bank of the river Yamuna in the Indian city of Agra.\"\n",
    "]\n",
    "\n",
    "paragraphs = np.array(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for paragraphs\n",
    "corpus_embeddings = model.encode(paragraphs)\n",
    "print(corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cf337",
   "metadata": {},
   "source": [
    "Now, let's define a function to perform semantic search, given a query and a list of paragraph embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, model, corpus_embeddings, paragraphs, top_k=2):\n",
    "    query_embedding = model.encode([query])[0]\n",
    "    similarities = cosine_similarity([query_embedding], corpus_embeddings)[0]\n",
    "    indexes = np.argpartition(similarities, -top_k)[-top_k:]\n",
    "    indexes = indexes[np.argsort(-similarities[indexes])]\n",
    "    print(f\"Input query: {query}\")\n",
    "    print()\n",
    "    for text, sim in zip(list(paragraphs[indexes]), similarities[indexes].tolist()):\n",
    "        print(f\"{sim:.3f}\\t{text}\")\n",
    "              \n",
    "\n",
    "semantic_search('Where is the Colosseum', model, corpus_embeddings, paragraphs, top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2c8e5",
   "metadata": {},
   "source": [
    "## Multilingual models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try in other languages\n",
    "semantic_search('¿Dónde está el Coliseo?', model, corpus_embeddings, paragraphs, top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd917e55",
   "metadata": {},
   "source": [
    "We have multilinguals models available [here](https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use multilingual models \n",
    "model_name = 'clip-ViT-B-32-multilingual-v1'\n",
    "multi_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_corpus_embeddings = multi_model.encode(paragraphs)\n",
    "print(multi_corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search('¿Dónde está el Coliseo?', multi_model, multi_corpus_embeddings, paragraphs, top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a984f",
   "metadata": {},
   "source": [
    "## Wikipedia semantic search\n",
    "\n",
    "As dataset, we use Simple English Wikipedia. Compared to the full English wikipedia, it has only\n",
    "about 170k articles. We split these articles into paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_filepath = 'data/simplewiki-2020-11-01.jsonl.gz'\n",
    "\n",
    "if not os.path.exists(wikipedia_filepath):\n",
    "    util.http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)\n",
    "\n",
    "passages = []\n",
    "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        data = json.loads(line.strip())\n",
    "        for paragraph in data['paragraphs']:\n",
    "            # We encode the passages as [title, text]\n",
    "            passages.append(data['title']+':  '+ paragraph)\n",
    "\n",
    "# If you like, you can also limit the number of passages you want to use\n",
    "print(\"Passages:\", len(passages))\n",
    "print(passages[0])\n",
    "print(passages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_passages = np.array(passages[:5000])\n",
    "reduced_passages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = model.encode(reduced_passages, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffec2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search('Best american actor', model, corpus_embeddings, reduced_passages, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d98fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search('Number countries Europe', model, corpus_embeddings, reduced_passages, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364a2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f8e570",
   "metadata": {},
   "source": [
    "### Question1: Load a different pre-trained Sentence Transformer model and compare its performance to the last model on the same set of paragraphs and queries. Which model performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a different pre-trained model, generate embeddings, and test with the same queries\n",
    "model_name = ...\n",
    "new_model = SentenceTransformer(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
